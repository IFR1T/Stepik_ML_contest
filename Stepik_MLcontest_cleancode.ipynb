{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# В начале идут агрегирующие функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_data_form(events_data, submission_data, sessions_quantile=0.95, leave_quantile=0.9, max_time_month=3, test=False):\n",
    "    \"\"\"Функция, чтобы запустить весь цикл функций для тренировочного датасета\"\"\"\n",
    "    total_data_df = total_data(events_data, submission_data, leave_quantile, max_time_month, test,\n",
    "                               finished_course, timediff, still_learning, first_n_days_df)\n",
    "    user_data = user_df(total_data_df, sessions_quantile, sessions, avg_time, first_day_features, maxdelta, wrong_only)\n",
    "    return user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_data(events_data, submission_data, leave_quantile=0.9, max_time_month=3, test=False, *args):\n",
    "    \"\"\"Функция для формирования единого датафрейма полных данных, с необходимыми дополнительными фичами\"\"\"\n",
    "    \n",
    "    submission_data = submission_data.rename(columns={'submission_status': 'action'})\n",
    "    total_data = events_data.append(submission_data)\n",
    "    total_data = pd.get_dummies(total_data) \\\n",
    "        .rename(columns={'action_correct': 'correct', 'action_discovered': 'discovered', 'action_passed': 'passed',\n",
    "                    'action_started_attempt': 'started_attempt', 'action_viewed': 'viewed', 'action_wrong': 'wrong',\n",
    "                    'finished_course_True': 'finished_course'})\n",
    "    for func in args:\n",
    "        if func == still_learning:\n",
    "            total_data = func(total_data, leave_quantile=leave_quantile, max_time_month=max_time_month)\n",
    "        elif func == first_n_days_df:\n",
    "            total_data = func(total_data, test=test)\n",
    "        else:    \n",
    "            total_data = func(total_data)\n",
    "    return total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_df(total_data, sessions_quantile=0.95, *args):\n",
    "    \"\"\"Функция, чтобы превратить исходный датафрейм в полный датафрейм по юзерам, с добавлением фич\"\"\"\n",
    "    user_data = total_data.groupby('user_id', as_index=False).agg({'correct': 'sum', 'discovered': 'sum', 'passed': 'sum', \n",
    "                                                         'started_attempt': 'sum', 'viewed': 'sum', 'wrong': 'sum', \n",
    "                                                         'finished_course': 'mean' ,'step_id': lambda x: x.nunique(),\n",
    "                                                                  'timestamp': 'min'}) \\\n",
    "                    .rename(columns={'step_id': 'steps_passed'})\n",
    "    user_data['total_actions'] = user_data.correct + user_data.discovered \\\n",
    "        + user_data.passed + user_data.started_attempt + user_data.viewed + user_data.wrong\n",
    "    user_data['correct_rate'] = user_data.correct / (user_data.correct + user_data.wrong)\n",
    "    user_data['viewed_rate'] = user_data.viewed / (user_data.total_actions)\n",
    "    \n",
    "    for func in args:\n",
    "        if func == sessions:\n",
    "            user_data = user_data.merge(func(total_data, sessions_quantile), on='user_id', how='outer')\n",
    "        else:    \n",
    "            user_data = user_data.merge(func(total_data), on='user_id', how='outer')\n",
    "        if func == first_day_features:\n",
    "            user_data['first_day_actions_rate'] = user_data.total_actions_1_day / user_data.total_actions\n",
    "            user_data['first_day_correct_rate'] = user_data.correct_1_day / \\\n",
    "                (user_data.correct_1_day + user_data.wrong_1_day)\n",
    "            user_data['corrects_rate_diff'] = user_data.first_day_correct_rate / user_data.correct_rate\n",
    "    return user_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# После агрегириющих функций - функции, преобразующие \"большой\" датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finished_course(total_data, min_corrects=41):\n",
    "    \"\"\"Функция для формирования в исходном датафрейме колонки finished_course. min_corrects - число правильных \n",
    "        ответов, с которого курс считается пройденым, по дефолту берется из условия задачи\"\"\"\n",
    "        \n",
    "    finished_course_data = total_data.query('correct == 1') \\\n",
    "        .groupby(['user_id', 'step_id'], as_index=False) \\\n",
    "        .agg({'correct': 'count'}) \\\n",
    "        .groupby('user_id', as_index=False) \\\n",
    "        .agg({'step_id': 'count'}) \\\n",
    "        .rename(columns={'step_id': 'correct_tasks'})\n",
    "    finished_course_data['finished_course'] = finished_course_data.correct_tasks >= min_corrects\n",
    "    total_data = total_data.merge(finished_course_data, on='user_id', how='outer').fillna(False)\n",
    "    return total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timediff(total_data):\n",
    "    \"\"\"Функция чтобы добавить в датафрейм колонку datadiff - показывает разницу во времени между действиями юзера\"\"\"\n",
    "    \n",
    "    total_data = total_data.sort_values(['user_id', 'timestamp'], ascending=False)\n",
    "    total_data['previous_action'] = total_data.timestamp.shift(-1)\n",
    "    total_data['previous_user'] = total_data.user_id.shift(-1)\n",
    "    total_data['timediff'] = (total_data.timestamp - total_data.previous_action) \\\n",
    "    * (total_data.user_id == total_data.previous_user)\n",
    "    total_data.drop(['previous_action', 'previous_user'], axis=1)\n",
    "    return total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def still_learning(total_data, leave_quantile=0.9, max_time_month=3):\n",
    "    \"\"\"Функция чтобы добавить в датафрейм колонку still_learning - показывает юзеров, которые на текущий момент еще, \n",
    "        возможно, учатся. leave_quantile - для определения порогового значения, сколько времени должно пройти между \n",
    "        действиями, чтобы юзер считался ушедшим. max_time_month - максимальный период (в месяцах), который используется\n",
    "        в расчете (чтобы исключить выбросы)\"\"\"\n",
    "        \n",
    "    max_time = max_time_month * 30 * 24 * 60 * 60\n",
    "    time_to_leave = total_data.query(f'timediff < {max_time}').groupby('user_id', as_index=False) \\\n",
    "        .agg({'timediff': 'max'}) \\\n",
    "        .timediff \\\n",
    "        .quantile(leave_quantile)\n",
    "    time_now = total_data.timestamp.max()\n",
    "    still_learning_time = time_now - time_to_leave\n",
    "    total_data['still_learning'] = total_data.timestamp >= still_learning_time\n",
    "    users_still_learning = total_data.query('still_learning == True') \\\n",
    "        .groupby('user_id', as_index=False).agg({'still_learning': 'max'}) \\\n",
    "        .rename(columns={'still_learning': 'users_still_learning'})\n",
    "    total_data = total_data.merge(users_still_learning, on='user_id', how='outer') \\\n",
    "        .fillna(False).drop(['still_learning'], axis=1) \\\n",
    "        .rename(columns={'users_still_learning': 'still_learning'})\n",
    "    return total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_n_days_df(total_data, n=2, test=False):\n",
    "    \"\"\"Функция чтобы оставить в датафрейме информацию только\n",
    "    о первых n днях обучения юзера. n=2, т.к. в тестовом дф данные за 2 дня\"\"\"\n",
    "    time = n * 24 * 60 * 60\n",
    "    users_start_time = total_data.groupby('user_id', as_index=False) \\\n",
    "        .agg({'timestamp': 'min'}) \\\n",
    "        .rename(columns={'timestamp': 'start_time'})\n",
    "    total_data = total_data.merge(users_start_time, on='user_id', how='outer')\n",
    "    if test == False:\n",
    "        total_data = total_data.query('(timestamp - start_time <= 172800) & ((finished_course == True) | (still_learning == False))')\n",
    "    return total_data.drop('still_learning', axis=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции, создающие фичи для юзерского датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_time(total_data):\n",
    "    \"\"\"Функция, чтобы по каждому юзеру подготовить фичу 'среднее время выполнения задания'\"\"\"\n",
    "    data_for_attempt_count = total_data.query('(started_attempt == 1) | (correct == 1)')\\\n",
    "                                    .sort_values(['user_id', 'step_id', 'timestamp', 'correct'])\n",
    "    data_for_attempt_count['attempt_start_time'] = data_for_attempt_count.timestamp.shift(1)\n",
    "    data_for_attempt_count['time_on_attempt'] = \\\n",
    "        (data_for_attempt_count.timestamp \\\n",
    "         - data_for_attempt_count.attempt_start_time) * data_for_attempt_count.correct\n",
    "    avg_time_for_attempt = data_for_attempt_count.query('correct == 1')\\\n",
    "        .groupby('user_id', as_index=False).agg({'time_on_attempt': 'mean'}) \\\n",
    "        .rename(columns={'time_on_attempt': 'avg_time_on_attempt'})\n",
    "    return avg_time_for_attempt[['user_id', 'avg_time_on_attempt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sessions(total_data, session_quatile=0.95):\n",
    "    \"\"\"Функция, чтобы по каждому юзеру подготовить фичу 'число сессий'\"\"\"\n",
    "    sessions_delta_min = total_data['timediff'].quantile(session_quatile)\n",
    "    sessions_data = total_data.query(f'timediff > {sessions_delta_min}')\\\n",
    "        .groupby('user_id', as_index=False) \\\n",
    "        .agg({'timediff': lambda x: x.count()}) \\\n",
    "        .rename(columns={'timediff':'sessions'}) \\\n",
    "        .sort_values('sessions')\n",
    "    return sessions_data[['user_id', 'sessions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_day_features(total_data):\n",
    "    \"\"\"Функция, чтобы добавить в юзерский датафрейм фичи, связанные с первым днем обучения\"\"\"\n",
    "    total_data_1_day = total_data.query('timestamp - start_time <= 86400')\n",
    "    user_data_1_day = total_data_1_day.groupby('user_id', as_index=False).agg({'correct': 'sum', 'discovered': 'sum', 'passed': 'sum', \n",
    "                                                         'started_attempt': 'sum', 'viewed': 'sum', 'wrong': 'sum', \n",
    "                                                        'step_id': lambda x: x.nunique()}) \\\n",
    "            .rename(columns={'correct': 'correct_1_day', 'discovered': 'discovered_1_day', 'passed': 'passed_1_day', \n",
    "                    'started_attempt': 'started_attempt_1_day', 'viewed': 'viewed_1_day', 'wrong': 'wrong_1_day', \n",
    "                   'step_id': 'steps_passed_1_day'})\n",
    "    user_data_1_day['total_actions_1_day'] = user_data_1_day.correct_1_day + user_data_1_day.discovered_1_day \\\n",
    "        + user_data_1_day.passed_1_day + user_data_1_day.started_attempt_1_day \\\n",
    "        + user_data_1_day.viewed_1_day + user_data_1_day.wrong_1_day\n",
    "    return user_data_1_day[['user_id', 'correct_1_day', 'wrong_1_day', 'total_actions_1_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxdelta(total_data):\n",
    "    \"\"\"Функция, чтобы добавить в юзерский датафрейм фичу \"время между первым и последним событием юзера в дф\" \"\"\"\n",
    "\n",
    "    df = total_data.groupby('user_id', as_index=False)\\\n",
    "        .agg({'timestamp': 'max', 'start_time': 'mean'}).rename(columns={'timestamp': 'maxtime'})\n",
    "    df['maxdelta'] = df['maxtime'] - df['start_time']\n",
    "    return df[['user_id', 'maxdelta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong_only(total_data):\n",
    "    \"\"\"Функция, чтобы добавить в юзерский датафрейм фичу \"количество шагов, которые юзер пытался решить, но не решил\" \"\"\"\n",
    "    \n",
    "    df = total_data.groupby(['step_id', 'user_id'], as_index=False)\\\n",
    "        .agg({'correct': 'sum', 'wrong': 'sum'}) \\\n",
    "        .query('correct == 0 & wrong != 0')\\\n",
    "        .groupby('user_id', as_index=False) \\\n",
    "        .agg({'wrong': 'count'}) \\\n",
    "        .rename(columns={'wrong': 'wrong_only'})\n",
    "    return df[['user_id', 'wrong_only']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции для подбора оптимальной структуры модели. Работают долго"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_parametrs(events_data_train, submission_data_train):\n",
    "    \"\"\"Функция для определения с помощью оптимальных констант: sessions_quantile, leave_quantile, max_time_month, min_corrects. Функция\n",
    "    работает очень долго, нужна оптимизация алгоритма, чтобы ей пользоваться на регулярной основе. Текущие параметры подобраны\n",
    "    с ее помощью\"\"\"\n",
    "    result = {}\n",
    "    parametrs = {'criterion': ['gini', 'entropy'],\n",
    "             'n_estimators': range(10, 101, 10), \n",
    "             'max_depth': range(4, 9, 1),\n",
    "             'min_samples_leaf': range(2, 10, 1),\n",
    "             'min_samples_split': range(10, 40, 5)}\n",
    "    for sessions_quantile in [85, 90, 95]:\n",
    "        for leave_quantile in [85, 90, 95]:\n",
    "            for max_time_month in [2, 5, 8]:\n",
    "                user_data_train = user_data_form(events_data_train, submission_data_train, sessions_quantile=sessions_quantile/100, \n",
    "                                                    leave_quantile=leave_quantile/100, max_time_month=max_time_month, min_corrects=min_corrects)\n",
    "                X_full = drop_features(user_data_train, drop_parametrs)\n",
    "                y_full = user_data_train.finished_course\n",
    "                X_f_train, X_f_test, y_f_train, y_f_test = train_test_split(X_full, y_full, test_size=0.25, random_state=42)\n",
    "                rf = RandomForestClassifier(random_state=0)\n",
    "                random_search = RandomizedSearchCV(rf, parametrs, cv=5, n_jobs=-1)\n",
    "                random_search.fit(X_f_train, y_f_train)\n",
    "                best_rf = random_search.best_estimator_\n",
    "                best_rf_score = roc_auc_score(y_f_test, best_rf.predict_proba(X_f_test)[:, 1])\n",
    "                result[tuple(list([sessions_quantile, leave_quantile, max_time_month, min_corrects]))] = best_rf_score\n",
    "    result_list = sorted(list(result.items()), key=lambda x: x[1], reverse=True)\n",
    "    return result_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_compilations(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Функция для сравнения возможных комбинаций фич, и выбора оптимальной. На большом количестве фич функция работает\n",
    "    долго, так что проводить какую-то предобработку, оставлять максимум 5-10 фич\"\"\"\n",
    "    features = list(X_train)\n",
    "    results = {}\n",
    "    for i in range(len(features) - 1):\n",
    "        for combination in combinations(features, i):\n",
    "            X_train_combination, X_test_combination = X_train, X_test\n",
    "            for feature in combination:\n",
    "                X_train_combination = X_train_combination.drop(feature, axis=1)\n",
    "                X_test_combination = X_test_combination.drop(feature, axis=1)\n",
    "            rf = RandomForestClassifier(random_state=0)\n",
    "            random_search = RandomizedSearchCV(rf, parametrs, cv=5, n_jobs=-1)\n",
    "            random_search.fit(X_train_combination, y_train)\n",
    "            best_rf = random_search.best_estimator_\n",
    "            best_rf_score = roc_auc_score(y_test, best_rf.predict_proba(X_test_combination)[:, 1])\n",
    "            results[combination] = best_rf_score\n",
    "    res2 = sorted(list(results.items()), key=lambda x: x[1], reverse=True)\n",
    "    return res2[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция для удаления фич из датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features(df, features):\n",
    "    \"\"\"Функция для удаления атрибутов датафрейма\"\"\"\n",
    "    \n",
    "    for feature in features:\n",
    "        df = df.drop(feature, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тело программы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Считываем файлы, обработка датафремов, формирование целевого юзерского датафрейма\n",
    "submission_data_train = pd.read_csv('submissions_data_train.csv')\n",
    "events_data_train = pd.read_csv('event_data_train.csv')\n",
    "user_data_train = user_data_form(events_data_train, submission_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сплит на трейн/тестовые датафреймы, которые используются для подбора оптимального набора фич. \n",
    "drop_parametrs = ['finished_course', 'user_id', 'steps_passed', \\\n",
    "                                           'viewed', 'started_attempt', 'discovered', 'passed',\\\n",
    "                                           'wrong_1_day', 'total_actions_1_day']\n",
    "pre_split_df = drop_features(user_data_train, drop_parametrs)\n",
    "X_f_train, X_f_test, y_f_train, y_f_test = \\\n",
    "train_test_split(pre_split_df, user_data_train.finished_course, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Формирование случайного леса\n",
    "rf = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "parametrs = {'criterion': ['gini', 'entropy'],\n",
    "             'n_estimators': range(100, 101, 1), \n",
    "             'max_depth': range(6, 7, 1),\n",
    "             'min_samples_leaf': range(10, 11, 1),\n",
    "             'min_samples_split': range(30, 31, 1)}\n",
    "grid_search = GridSearchCV(rf, parametrs, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_f_train, y_f_train)\n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8492470749674996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=6,\n",
       "                       min_samples_leaf=10, min_samples_split=30,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Смотрим результат, обучаем лес на полных данных\n",
    "\n",
    "print(roc_auc_score(y_f_test, best_rf.predict_proba(X_f_test)[:, 1]))\n",
    "X_full = drop_features(user_data_train, drop_parametrs)\n",
    "y_full = user_data_train.finished_course\n",
    "best_rf.fit(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Предобработка тестового датафрейма\n",
    "submission_data_test = pd.read_csv('submission_data_test.csv')\n",
    "events_data_test = pd.read_csv('events_data_test.csv')\n",
    "user_data_test = user_data_form(events_data_test, submission_data_test, test=True)\n",
    "X_test = drop_features(user_data_test, drop_parametrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получение результата\n",
    "y_predicted_prob = best_rf.predict_proba(X_test)\n",
    "result = pd.DataFrame({'user_id': user_data_test['user_id'], '\"is_gone\"': y_predicted_prob[:,1]})\n",
    "result.to_csv(r'C:\\Users\\Solovov\\Dropbox\\GoT\\Projects\\Stepik_ML_contest\\test_result.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
